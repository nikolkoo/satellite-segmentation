{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9246ecad",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook partitions Sentinel‑2 RGB imagery into 256×256 patches and generates aligned image–mask pairs using ESA WorldCover masks via the Microsoft Planetary Computer STAC API. Key steps covered:\n",
    "- search and download suitable Sentinel‑2 and WorldCover assets for a given bbox/year.\n",
    "- reproject/resample WorldCover to the Sentinel grid (nearest for categorical masks).\n",
    "- verify alignment (size, CRS, transform) and tile into image–mask pairs.\n",
    "- save patches for training or publishing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a197bdbd",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7363957",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torchgeo\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b6a47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from torchgeo.models import ResNet18_Weights, ResNet50_Weights, resnet18, resnet50\n",
    "from pathlib import Path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bb870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code written with ChatGPT-5\n",
    "def find_repo_root(start: Path = Path.cwd(), markers=(\"pyproject.toml\", \"setup.py\", \".git\", \"README.md\")) -> Path:\n",
    "    \"\"\"_summary_\n",
    "    Set the folder to the current path for correct folder alignment. \n",
    "    \"\"\"\n",
    "    p = start.resolve()\n",
    "    while True:\n",
    "        if any((p / m).exists() for m in markers):\n",
    "            return p\n",
    "        if p.parent == p: \n",
    "            return start.resolve()\n",
    "        p = p.parent\n",
    "\n",
    "repo_root = find_repo_root()\n",
    "sys.path.insert(0, str(repo_root))\n",
    "\n",
    "print(\"repo_root:\", repo_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4b399f",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "We use Microsoft Planetary Computer Stack as the backbone API to collect image pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7c0ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Connect to Microsoft Planetary Computer STAC Catalog\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "from planetary_computer import sign_url\n",
    "from shapely.geometry import box, mapping\n",
    "\n",
    "# Variables specifying the position, year and crop sizes\n",
    "bbox = [10.65, 59.85, 10.85, 59.95]\n",
    "geom = mapping(box(bbox[0], bbox[1], bbox[2], bbox[3]))\n",
    "year = 2021\n",
    "crop_size = 256\n",
    "\n",
    "# https://pystac-client.readthedocs.io/en/stable/usage.html#loading-data\n",
    "# Load the Microsoft Stac client\n",
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6f410b",
   "metadata": {},
   "source": [
    "#### Masks\n",
    "We use the masks generated by ESA WorldCover. This is one of the biggest generated segmentation maps, and has been widely used due to it's good precision and simplicity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580c2867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESA world cover\n"
     ]
    }
   ],
   "source": [
    "# --- ESA WorldCover ---\n",
    "print(\"ESA world cover\")\n",
    "search_mask = catalog.search(\n",
    "    max_items = 1,\n",
    "    intersects = geom,\n",
    "    collections=[\"esa-worldcover\"],\n",
    "    datetime=f\"{year}-01-01/{year}-12-31\"\n",
    ")\n",
    "mask_items = search_mask.item_collection()\n",
    "\n",
    "if len(mask_items) == 0:\n",
    "    raise ValueError(\"No WorldCover data found for this location.\")\n",
    "\n",
    "selected_mask_item = mask_items[0]\n",
    "\n",
    "asset_items = selected_mask_item.assets.items()\n",
    "\n",
    "asset_key = \"map\" # Get the full rgb image directly\n",
    "href = selected_mask_item.assets[asset_key].href\n",
    "signed_hrf = sign_url(href)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623af994",
   "metadata": {},
   "source": [
    "#### Images\n",
    "The images are taken from raw images taken by the Sentinel-2 satellite. We select the RGB bands and filter for 10% cloud-coverage to find the best raster's within the timespan selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "024413ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentinel2\n"
     ]
    }
   ],
   "source": [
    "from src.data.patchify_data import save_as_images\n",
    "# --- Sentinel-2 ---\n",
    "print(\"Sentinel2\")\n",
    "search_s2 = catalog.search(\n",
    "    max_items = 1,\n",
    "    collections=[\"sentinel-2-l2a\"],\n",
    "    intersects=geom,\n",
    "    datetime=f\"{year}-01-01/{year}-12-31\",\n",
    "    query={\"eo:cloud_cover\": {\"lt\": 10}}, # Less than 10% clouds\n",
    "    sortby=[{'field': 'eo:cloud_cover', 'direction': 'asc'}] # Get the clearest one\n",
    ")\n",
    "s2_items = search_s2.item_collection()\n",
    "\n",
    "if len(s2_items) == 0:\n",
    "    raise ValueError(\"No clear Sentinel-2 images found.\")\n",
    "    \n",
    "selected_s2_item = s2_items[0]\n",
    "asset_items = selected_s2_item.assets.items()\n",
    "\n",
    "asset_key = \"visual\" # Get the full rgb image directly\n",
    "href = selected_s2_item.assets[asset_key].href\n",
    "signed_hrf = sign_url(href)\n",
    "\n",
    "#save_as_images(signed_hrf, bands=(1,2,3), img_size=256, img_prefix=\"sentinel2\", out_directory=\"sentinel_patches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110d9837",
   "metadata": {},
   "source": [
    "#### Inspect elements\n",
    "We perform a simple size check to see if the patches align in size. This is crucial to get accurate image-mask pairs for image segmentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf0cf1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worldcover width,height: 36000 36000\n",
      "  tiles (ceil): 141 x 141 = 19881\n",
      "  dtype,count: ('uint8',) 1\n",
      "sentinel2 width,height: 10980 10980\n",
      "  tiles (ceil): 43 x 43 = 1849\n",
      "  dtype,count: ('uint8', 'uint8', 'uint8') 3\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "import rasterio\n",
    "from planetary_computer import sign_url\n",
    "\n",
    "mask_href = sign_url(selected_mask_item.assets[\"map\"].href)\n",
    "s2_href   = sign_url(selected_s2_item.assets[\"visual\"].href)\n",
    "\n",
    "for name, href in [(\"worldcover\", mask_href), (\"sentinel2\", s2_href)]:\n",
    "    with rasterio.open(href) as src:\n",
    "        w,h = src.width, src.height\n",
    "        print(name, \"width,height:\", w, h)\n",
    "        tile = 256\n",
    "        ncols = ceil(w / tile)\n",
    "        nrows = ceil(h / tile)\n",
    "        print(\"  tiles (ceil):\", nrows, \"x\", ncols, \"=\", nrows*ncols)\n",
    "        print(\"  dtype,count:\", src.dtypes, src.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc1fb9d",
   "metadata": {},
   "source": [
    "#### Preprocessing with transformation\n",
    "Using rasterio leads to different trasnforms due to their type. We therefore need to either transform the images or use odc.stac.load. Here we use rasterio transform as this module is used in other parts of the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e321c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import rasterio\n",
    "from rasterio.vrt import WarpedVRT\n",
    "from rasterio.enums import Resampling\n",
    "from planetary_computer import sign_url\n",
    "import numpy.testing as npt\n",
    "\n",
    "from src.data.patchify_data import save_as_mask_pairs\n",
    "\n",
    "# TODO: add this to utils\n",
    "def align_mask_to_reference(mask_href, ref_href, out_path=None):\n",
    "    \"\"\"_summary_\n",
    "    Reproject/resample single-band categorical mask (mask_href) to the grid of ref_href.\n",
    "    Returns local GeoTIFF path you can pass to save_as_mask unchanged.\n",
    "    \"\"\"\n",
    "    if out_path is None:\n",
    "        tmp = tempfile.NamedTemporaryFile(suffix=\".tif\", delete=False)\n",
    "        out_path = tmp.name\n",
    "        tmp.close()\n",
    "\n",
    "    with rasterio.open(ref_href) as ref:\n",
    "        profile = ref.profile.copy()\n",
    "        # single-band categorical mask\n",
    "        profile.update(driver=\"GTiff\", count=1, dtype=\"uint8\", compress=\"deflate\", tiled=True)\n",
    "\n",
    "        with rasterio.open(mask_href) as src:\n",
    "            with WarpedVRT(\n",
    "                src,\n",
    "                crs=ref.crs,\n",
    "                transform=ref.transform,\n",
    "                width=ref.width,\n",
    "                height=ref.height,\n",
    "                resampling=Resampling.nearest,\n",
    "            ) as vrt:\n",
    "                with rasterio.open(out_path, \"w\", **profile) as dst:\n",
    "                    dst.write(vrt.read(1), 1)\n",
    "\n",
    "    return out_path\n",
    "\n",
    "mask_href = selected_mask_item.assets[\"map\"].href\n",
    "s2_href   = selected_s2_item.assets[\"visual\"].href\n",
    "\n",
    "aligned_mask_tif = align_mask_to_reference(sign_url(mask_href), sign_url(s2_href))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31659349",
   "metadata": {},
   "source": [
    "#### Save as pairs\n",
    "We now have aligned image-mask pairs that have been correctly preprocessed. The last step is to save the images and perform a simple check that the pairs align. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bfcba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create this as a test! (written with ChatGPT-5)\n",
    "with rasterio.open(sign_url(s2_href)) as s2, rasterio.open(aligned_mask_tif) as m:\n",
    "    assert (s2.width, s2.height) == (m.width, m.height), \\\n",
    "        f\"size mismatch: s2={s2.width}x{s2.height}, mask={m.width}x{m.height}\"\n",
    "    assert s2.crs == m.crs, f\"CRS mismatch: s2={s2.crs}, mask={m.crs}\"\n",
    "    # transforms are Affine; allow tiny numerical tolerance\n",
    "    npt.assert_allclose(tuple(s2.transform), tuple(m.transform), atol=1e-6, rtol=0)\n",
    "    assert m.count == 1, f\"mask has {m.count} bands (expected 1)\"\n",
    "    print(\"PASS: aligned_mask_tif matches Sentinel-2 grid (width,height,crs,transform)\")\n",
    "\n",
    "save_as_mask_pairs(aligned_mask_tif, sign_url(s2_href))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
